{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "Rlp5wUW_FDmH",
    "outputId": "375cb352-57f9-4bc4-aa5b-8a9824e8cad2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# Import ME PLEASE\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "#pip install --upgrade tensorflow  \n",
    "# now we use tensorflow 2 \n",
    "#lets hope that your current libraries will not be destroyed :(\n",
    "#if it happens, you can always downgrade it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MNIST dataset is, in general, highly processed already - after all its 28x28 grayscale images \n",
    "# When finally deploying a model in practice, include the prerpocessing as initial layers!\n",
    "# In that way, the users could just plug the data (images) directly, instead of being required to resize/rescale it before\n",
    "# REMEMBER TRANSFER LEARNING SECTION,  you were able to send any size of picture to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 70_000 # for reshuffling\n",
    "BATCH_SIZE = 128 # big batch size speeds up the training\n",
    "#lower batch size can give better # use the power of 2.  as  2,4,8,32,64,128  (DESIRABLE---------I have dark desires to use 128 in a CNN, you thought something else :D)\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Download the MNIST dataset\n",
    "# When 'with_info' is set to True, tfds.load() returns two variables: \n",
    "# - the dataset train and test\n",
    "# - metadata\n",
    "\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "# mnist_dataset  data is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Extracting the train and test datasets\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test'] # obviously easy in MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32) # cast it to float32 using tf\n",
    "    image /= 255. # oh look its manual min max scaler for MATH FANS\n",
    "# numbers vary 0 to 255 \n",
    "# but we will scale this value between 0 to 1\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " # scale me\n",
    "train_and_validation_data = mnist_train.map(scale) # map everything to SCALE and SAVE\n",
    "test_data = mnist_test.map(scale) # dont be scared, map()  applies your function to DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Define the size of VALIDATION SET,  ( i recommend)\n",
    "num_validation_samples = 0.1* mnist_info.splits['train'].num_examples  # 10% will be validation\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Define the size of TEST  SET\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64) # cast it to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# shuffle ( HOPEFULLY YOU REMEMBER)\n",
    "train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training + validation\n",
    "train_data = train_and_validation_data.skip(num_validation_samples) # dont return validation set\n",
    "validation_data = train_and_validation_data.take(num_validation_samples) # take validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Batching the data\n",
    "# dont take everything into memory take using BATCH, this is not a small dataset\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples) \n",
    "test_data = test_data.batch(num_test_samples)\n",
    "#its for optimal performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Super HOT XXX CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CONV -> MAXPOOL -> CONV -> MAXPOOL -> FLATTEN -> DENSE\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, 5, activation='relu', input_shape=(28, 28, 1)), # input size depends on data!\n",
    "    \n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),# (2,2) is the default pool size, if you leave it blank its gonna be 2,2\n",
    "        #50 is, 50 kernels ( how many kernels im using)\n",
    "    tf.keras.layers.Conv2D(50, 3, activation='relu'), # here is different kernel as 3x3\n",
    "    #no need input shape again above!\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),  \n",
    "    \n",
    "    tf.keras.layers.Flatten(), # flatten everything\n",
    "    tf.keras.layers.Dense(10) #apply softmax activation LATER for fully connected NN (EXPLAINED BELOW)\n",
    "    #10 beacuse we have 10 classes!\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      " Layer (type)                    Output Shape                  Param #     \n",
      "===========================================================================\n",
      " conv2d (Conv2D)                 (None, 24, 24, 50)            1300        \n",
      "                                                                           \n",
      " max_pooling2d (MaxPooling2D)    (None, 12, 12, 50)            0           \n",
      "                                                                           \n",
      " conv2d_1 (Conv2D)               (None, 10, 10, 50)            22550       \n",
      "                                                                           \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 50)              0           \n",
      "                                                                           \n",
      " flatten (Flatten)               (None, 1250)                  0           \n",
      "                                                                           \n",
      " dense (Dense)                   (None, 10)                    12510       \n",
      "                                                                           \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A brief summary of your CNN Model\n",
    "model.summary(line_length = 75)\n",
    "#why none in the first, because we use batch, we just pass thousands of images all at once\n",
    "# but model does not know it yet, because we didnt train it NOT YET\n",
    "#TRAINABLE PARAMETERS ARE WEIGHTS OF OUR NETWORK\n",
    "#PERHAPS you would like to multiply your parameters by 2. ( this will be non-trainable, and we dont have it here)\n",
    "# we have 22550 in second layer because, we are not concentrating on the spatial dimension but think\n",
    "#of  its the third dimension of the input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE softmatx into LOSS FUNCTION\n",
    "\n",
    "# model needs to output probabilities of each class, \n",
    "# which can be achieved with a softmax activation in the last dense layer\n",
    "\n",
    "\n",
    "# we use a loss calculation that automatically corrects for the missing softmax\n",
    "\n",
    "# That is the reason for 'from_logits=True' #tells TF to use softmax into loss function\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with ADAM optimizer and the categorical crossentropy (loss function)\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining early stopping to prevent overfitting if validation loss increases\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(  #callback\n",
    "    monitor = 'val_loss', # stops traininig when validation starts to increase for 2 subsequent epochs\n",
    "    mode = 'auto',     # you can always change it\n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0, \n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "422/422 - 42s - loss: 0.2716 - accuracy: 0.9206 - val_loss: 0.0878 - val_accuracy: 0.9720 - 42s/epoch - 99ms/step\n",
      "Epoch 2/3\n",
      "422/422 - 27s - loss: 0.0734 - accuracy: 0.9778 - val_loss: 0.0538 - val_accuracy: 0.9830 - 27s/epoch - 65ms/step\n",
      "Epoch 3/3\n",
      "422/422 - 27s - loss: 0.0538 - accuracy: 0.9835 - val_loss: 0.0362 - val_accuracy: 0.9892 - 27s/epoch - 65ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d19ffe4f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the network\n",
    "model.fit(\n",
    "    train_data, \n",
    "    epochs = NUM_EPOCHS, \n",
    "    callbacks = [early_stopping],   #callbacks are always here for you\n",
    "    validation_data = validation_data,\n",
    "    verbose = 2  #what to print during the training, 2 means print only at the end of epoch\n",
    "    # verbose 1 will display progress bars for every batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0379 - accuracy: 0.9876\n"
     ]
    }
   ],
   "source": [
    "# Test your model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0379. Test accuracy: 98.76%\n"
     ]
    }
   ],
   "source": [
    "# print your hot content ( here is easy)\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spl test_data into 2 arrays, containing the images and their labels\n",
    "for images, labels in test_data.take(1):\n",
    "    images_test = images.numpy()\n",
    "    labels_test = labels.numpy()\n",
    "\n",
    "#Reshape images into 28x28 form, suitable for matplotlib because original dimensions were 28x28x1\n",
    "images_plot = np.reshape(images_test, (10000,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB7CAYAAACy7jQ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAADp0lEQVR4nO3dwSt0URzG8feKTAkpWc7CxqxIFDtZIAtK2VnNUllakKxlQTb+BAv5GyhLsrAgIaXYCQulSOZd/87tPTrd+5oz9/l+dk/m3Ln1OHNm7tx7J6nVan+gp6neO4D6oHhRFC+K4kVRvCiKF9Xs+2OSJHzWa2C1Wi3519+Y8aIoXhTFi6J4URQviuJFUbwoihdF8aIoXhTFi6J4URQviuJFUbwoihdF8aIoXpT31KtG097ebvLS0pL38ZOTkyaPjo6avL297c3Pz8+huxgNZrwoihdF8aIS39WysZ9e3dfXZ/Lp6anJbW1t3vFJYs8+/unK4ff3d5NXV1dN3t3d9Y7/bZxejRSKF0Xxohpqje/u7jZ5f3/f5LGxsaDtha7xro+PD5MPDw9Nnp2dDdpe3ljjkULxoiheVNTH6nt6ekze29szOXRNz1tra6vJ7nuQmDHjRVG8KIoXFfUaPzc3Z/L4+HjQ+K+vL5PX1tZMPj4+Nnl+ft7k5eXloOdrJMx4URQviuJFRb3GV6vVTONvbm5M3tra8j5+ZGQk0/M1Ema8KIoXRfGiol7jQ11dXZkc+n34wsJCpud/enrKNP43MeNFUbwoihdVqDX+7u7O5Pv7e+/jZ2ZmTB4cHMz0/Ds7O5nG/yZmvCiKF0XxoqJa4wcGBkwul8tB4x8eHoIePzQ0ZHJLS0vQ+Ovra5Nvb2+DxtcTM14UxYuK6qW+t7fXZPf06p90dnaaXCqVTF5fXzd5ZWXF5NBLqB4fH705Zsx4URQviuJFRX2Z9MnJicnDw8O5br+pyf7ff39/B413T9U6OzvLvE954jJppFC8KIoXFdXneJf7/iP0c/ZP3DU97+3HjBkviuJFUbyoqNf4zc1Nkw8ODuq0J8XDjBdF8aIoXlTUx+rd2467Px2yuLjoHd/f32+y+31/1luaurdUzXoJVt44Vo8UihdF8aKiXuOzqlQqJl9cXJicdY13b1M+NTUVNP5/Y41HCsWLonhRhV7jOzo6TH55eTE56xr/+vpq8sTEhMnn5+dB28sbazxSKF4UxYuK+vv42HV1dXlzzJjxoiheFMWLonhRFC+K4kVRvKhCf453j71/fn6a7P5EaChud4aGQ/GiCv1S//b2ZvL09LTJR0dHQdu7vLw0eWNjw2Rud4boUbwoihdV6FOv1HHqFVIoXhTFi6J4URQviuJFUbwoihdF8aIoXhTFi/Ieq0dxMeNFUbwoihdF8aIoXhTFi/oLI6LktY3Z1MYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 8\n"
     ]
    }
   ],
   "source": [
    "# The image to be displayed and tested\n",
    "i = 589\n",
    "\n",
    "# sad results below:\n",
    "# i=34 bad result!!!\n",
    "# i=589 will ruin this! (worst result)\n",
    "\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1], cmap=\"gray\", aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# Print the correct label for the image\n",
    "print(\"Label: {}\".format(labels_test[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain the model's predictions probabilities\n",
    "predictions = model.predict(images_test[i-1:i])\n",
    "\n",
    "# Convert those predictions into probabilities (incorporate the softmax activation into the loss function)\n",
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "# Convert the probabilities into percentages\n",
    "probabilities = probabilities*100\n",
    "# create your favorite barchart ( beautiful)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0], tick_label=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "defaultNotebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
