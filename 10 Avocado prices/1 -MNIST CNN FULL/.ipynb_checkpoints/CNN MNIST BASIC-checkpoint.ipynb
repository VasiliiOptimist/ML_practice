{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "Rlp5wUW_FDmH",
    "outputId": "375cb352-57f9-4bc4-aa5b-8a9824e8cad2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# Import ME PLEASE\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "#pip install --upgrade tensorflow  \n",
    "# now we use tensorflow 2 \n",
    "#lets hope that your current libraries will not be destroyed :(\n",
    "#if it happens, you can always downgrade it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MNIST dataset is, in general, highly processed already - after all its 28x28 grayscale images \n",
    "# When finally deploying a model in practice, include the prerpocessing as initial layers!\n",
    "# In that way, the users could just plug the data (images) directly, instead of being required to resize/rescale it before\n",
    "# REMEMBER TRANSFER LEARNING SECTION,  you were able to send any size of picture to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 70_000 # for reshuffling\n",
    "BATCH_SIZE = 128 # big batch size speeds up the training\n",
    "#lower batch size can give better # use the power of 2.  as  2,4,8,32,64,128  (DESIRABLE---------I have dark desires to use 128 in a CNN, you thought something else :D)\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Download the MNIST dataset\n",
    "# When 'with_info' is set to True, tfds.load() returns two variables: \n",
    "# - the dataset train and test\n",
    "# - metadata\n",
    "\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "# mnist_dataset  data is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Extracting the train and test datasets\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test'] # obviously easy in MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32) # cast it to float32 using tf\n",
    "    image /= 255. # oh look its manual min max scaler for MATH FANS\n",
    "# numbers vary 0 to 255 \n",
    "# but we will scale this value between 0 to 1\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " # scale me\n",
    "train_and_validation_data = mnist_train.map(scale) # map everything to SCALE and SAVE\n",
    "test_data = mnist_test.map(scale) # dont be scared, map()  applies your function to DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Define the size of VALIDATION SET,  ( i recommend)\n",
    "num_validation_samples = 0.1* mnist_info.splits['train'].num_examples  # 10% will be validation\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Define the size of TEST  SET\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64) # cast it to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# shuffle ( HOPEFULLY YOU REMEMBER)\n",
    "train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training + validation\n",
    "train_data = train_and_validation_data.skip(num_validation_samples) # dont return validation set\n",
    "validation_data = train_and_validation_data.take(num_validation_samples) # take validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Batching the data\n",
    "# dont take everything into memory take using BATCH, this is not a small dataset\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples) \n",
    "test_data = test_data.batch(num_test_samples)\n",
    "#its for optimal performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Super HOT XXX CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CONV -> MAXPOOL -> CONV -> MAXPOOL -> FLATTEN -> DENSE\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, 5, activation='relu', input_shape=(28, 28, 1)), # input size depends on data!\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),# (2,2) is the default pool size, if you leave it blank its gonna be 2,2\n",
    "        #50 is, 50 kernels ( how many kernels im using)\n",
    "    tf.keras.layers.Conv2D(50, 3, activation='relu'), # here is different kernel as 3x3\n",
    "    #no need input shape again above!\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),  \n",
    "    \n",
    "    tf.keras.layers.Flatten(), # flatten everything\n",
    "    tf.keras.layers.Dense(10) #apply softmax activation LATER for fully connected NN (EXPLAINED BELOW)\n",
    "    #10 beacuse we have 10 classes!\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      " Layer (type)                    Output Shape                  Param #     \n",
      "===========================================================================\n",
      " conv2d (Conv2D)                 (None, 24, 24, 50)            1300        \n",
      "                                                                           \n",
      " max_pooling2d (MaxPooling2D)    (None, 12, 12, 50)            0           \n",
      "                                                                           \n",
      " conv2d_1 (Conv2D)               (None, 10, 10, 50)            22550       \n",
      "                                                                           \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 50)              0           \n",
      "                                                                           \n",
      " flatten (Flatten)               (None, 1250)                  0           \n",
      "                                                                           \n",
      " dense (Dense)                   (None, 10)                    12510       \n",
      "                                                                           \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A brief summary of your CNN Model\n",
    "model.summary(line_length = 75)\n",
    "#why none in the first, because we use batch, we just pass thousands of images all at once\n",
    "# but model does not know it yet, because we didnt train it NOT YET\n",
    "#TRAINABLE PARAMETERS ARE WEIGHTS OF OUR NETWORK\n",
    "#PERHAPS you would like to multiply your parameters by 2. ( this will be non-trainable, and we dont have it here)\n",
    "# we have 22550 in second layer because, we are not concentrating on the spatial dimension but think\n",
    "#of  its the third dimension of the input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE softmatx into LOSS FUNCTION\n",
    "\n",
    "# model needs to output probabilities of each class, \n",
    "# which can be achieved with a softmax activation in the last dense layer\n",
    "\n",
    "\n",
    "# we use a loss calculation that automatically corrects for the missing softmax\n",
    "\n",
    "# That is the reason for 'from_logits=True' #tells TF to use softmax into loss function\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with ADAM optimizer and the categorical crossentropy (loss function)\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining early stopping to prevent overfitting if validation loss increases\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(  #callback\n",
    "    monitor = 'val_loss', # stops traininig when validation starts to increase for 2 subsequent epochs\n",
    "    mode = 'auto',     # you can always change it\n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0, \n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "422/422 - 26s - loss: 0.2706 - accuracy: 0.9245 - val_loss: 0.0872 - val_accuracy: 0.9743 - 26s/epoch - 63ms/step\n",
      "Epoch 2/3\n",
      "422/422 - 22s - loss: 0.0711 - accuracy: 0.9786 - val_loss: 0.0684 - val_accuracy: 0.9793 - 22s/epoch - 53ms/step\n",
      "Epoch 3/3\n",
      "422/422 - 25s - loss: 0.0538 - accuracy: 0.9831 - val_loss: 0.0407 - val_accuracy: 0.9877 - 25s/epoch - 58ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2210a012610>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the network\n",
    "model.fit(\n",
    "    train_data, \n",
    "    epochs = NUM_EPOCHS, \n",
    "    callbacks = [early_stopping],   #callbacks are always here for you\n",
    "    validation_data = validation_data,\n",
    "    verbose = 2  #what to print during the training, 2 means print only at the end of epoch\n",
    "    # verbose 1 will display progress bars for every batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0458 - accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "# Test your model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0458. Test accuracy: 98.50%\n"
     ]
    }
   ],
   "source": [
    "# print your hot content ( here is easy)\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spl test_data into 2 arrays, containing the images and their labels\n",
    "for images, labels in test_data.take(1):\n",
    "    images_test = images.numpy()\n",
    "    labels_test = labels.numpy()\n",
    "\n",
    "#Reshape images into 28x28 form, suitable for matplotlib because original dimensions were 28x28x1\n",
    "images_plot = np.reshape(images_test, (10000,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB7CAYAAACy7jQ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAE70lEQVR4nO2dSyh1axjHz3aJFLlE2qKkDAxICQMZUEohDCRGSoYoQmRmIqJcYqJkICUjGYgyIJIBA8lEuSS3gVzLdZ/JOfX9n3XOuz9n72Uv5/n/Zr/23mu93/fv9ax3rXe9r8vj8fxB9BEU6AaQwMDglcLglcLglcLglcLglRJi+tDlcnGs94PxeDyuf/uMPV4pDF4pDF4pDF4pDF4pDF4pDF4pDF4pDF4pDF4pDF4pDF4pDF4pDF4pDF4pxufxTmdychK8qanpS7+fnp4Gv7+/B19cXARfX18Hf319/dL5nAR7vFIYvFJcpjdpnD71qqCgADw+Ph58ZGQE3O12G4/ncuFMJfl/Mz4+Dj40NAR+fHxsPP53w6lXxAKDVwqDV8qPrvGSnJwc8OXlZfDo6Gjw0tJS8IaGBvCamhrj+WRNLykpAT86OjL+3m5Y44kFBq8UBq+UH1XjQ0NDwfPy8sDlLdaoqCjj8dLS0sBPT0/B29rawHt6esAjIyONvy8sLAQ/OzsztsffsMYTCwxeKQxeKT+qxldWVoIvLCyAf35+gu/s7IA/Pz8bj/f4+Gg8v7wmWF1dBU9JSQGX9/blNcPb25vxfL7CGk8sMHilMHilOLrG5+fng8txemxsLHhXVxf4wMAAeGJiIvjl5aVP7cvMzATf3d01fr+1tRV8dHTUp/N7gzWeWGDwSmHwSnF0je/v7wdvb28H//j4AE9KSgK/ubmxp2F/ERSE/aazsxO8r68PXI77y8rKwP09rmeNJxYYvFIYvFIcVePluFw+vw4PDwcfGxsDb2lpsadhv0lCQgL45uYmeGpqKrh85Wtqasqv7WGNJxYYvFIYvFIc9Zq0fF4ta/rBwQF4b2+v7W36CtfX1+DyPoKs8XI+gL9rvAn2eKUweKUweKU4qsaXl5cbP394eACXS5c4jb29PfDc3FxwOUfvO2GPVwqDV0pAb9kWFxeDr6ysGL9fV1cHPjc35/c22cnV1RW4vMVbVFQEvra25tP5eMuWWGDwSmHwSgnocC45ORlcXm/c3d2By5Ulfxry3ydf+fpO2OOVwuCVwuCVEtAaX1VVZfz85eUF/Pz83M7m+J2Ojg5wObXs9vYW/OLiwvY2/Q17vFIYvFIYvFIc9VhWMjExEegmfAm5HJtcEjU4OBh8fn4e/PDw0J6G/QPs8Uph8Eph8EpxdI2Pi4sLdBOMyJoutyrJzs4GPzk5AR8cHLSnYb8Be7xSGLxSGLxSAjrnrr6+HnxmZgb8/f0dXC4d4m2Ont00NzeDDw8PG7+flZUFvr+/7/c2/Qrn3BELDF4pDF4pAR3Hy+fr8nojJASb193dDb61tQX+9PRkPJ43wsLCwKurq8HlNUZFRYXxeHIrE/madyBhj1cKg1cKg1eKo5Y7k++Kye27vDE7Owu+tLQELsfNcktRuUVoRkaG8XxySVV5r166XCrFbjiOJxYYvFIYvFIcVePdbje43AbcW831FZcLS+L29ja4XHZctm9jY8Oehv1HWOOJBQavFAavFEfVeElMTAx4bW0teHp6OnhjYyN4RETEl84ntxKRW6PILUqdDms8scDgleLoP/XEN/innlhg8Eph8Eph8Eph8Eph8Eph8Eph8Eph8Eph8Eph8Eph8Eph8Eph8Eph8EoxPo8n/1/Y45XC4JXC4JXC4JXC4JXC4JXyJ5qvflaAU92kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# The image to be displayed and tested\n",
    "i = 555\n",
    "\n",
    "# sad results below:\n",
    "# i=34 bad result!!!\n",
    "# i=589 will ruin this! (worst result)\n",
    "\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1], cmap=\"gray\", aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# Print the correct label for the image\n",
    "print(\"Label: {}\".format(labels_test[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain the model's predictions probabilities\n",
    "predictions = model.predict(images_test[i-1:i])\n",
    "\n",
    "# Convert those predictions into probabilities (incorporate the softmax activation into the loss function)\n",
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "# Convert the probabilities into percentages\n",
    "probabilities = probabilities*100\n",
    "# create your favorite barchart ( beautiful)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0], tick_label=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "defaultNotebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
