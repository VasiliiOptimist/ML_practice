{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "Rlp5wUW_FDmH",
    "outputId": "375cb352-57f9-4bc4-aa5b-8a9824e8cad2"
   },
   "outputs": [],
   "source": [
    "# Importing the relevant packages\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "#hp is hyperparameters\n",
    "#lets tune kernel size  and optimizer  ( we will tune them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "\n",
    "BUFFER_SIZE = 70_000 # same as is\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Downloading the MNIST dataset\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Creating a function to scale our data\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# size of validation set\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining size of test set\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Reshuffle\n",
    "train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset \n",
    "train_data = train_and_validation_data.skip(num_validation_samples)\n",
    "validation_data = train_and_validation_data.take(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Batch\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hypermatarest we would test and their range\n",
    "HP_FILTER_SIZE = hp.HParam('filter_size', hp.Discrete([3,5,7])) #kernel size (different varitions)\n",
    "# 3,5 and 7 we will experiment\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "# lets experiment the optimizers adam and sgd\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "# you have TEST accuracy and we ARE NOT DISCUSSING IT UNLESS YOU WANT TO FAIL THIS COURSE\n",
    "\n",
    "# Logging setup info  # yes again log info\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_FILTER_SIZE, HP_OPTIMIZER],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create your model and training in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    # you change hparams[HP_FILTER_SIZE] as 3 5 and 7\n",
    "    # you change hparams[HP_OPTIMIZER]  for 2 different optimizers\n",
    "    # first copy paste your CNN model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(50, hparams[HP_FILTER_SIZE], activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(50, hparams[HP_FILTER_SIZE], activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    \n",
    "    # Define the loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Compiling the model with parameter value for the optimizer\n",
    "    model.compile(optimizer=hparams[HP_OPTIMIZER], loss=loss_fn, metrics=['accuracy'])\n",
    "    \n",
    "    # Defining early stopping to prevent overfitting\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0, \n",
    "        restore_best_weights = True\n",
    "    )\n",
    "    \n",
    "    # Training the model\n",
    "    model.fit(\n",
    "        train_data, \n",
    "        epochs = NUM_EPOCHS,\n",
    "        callbacks = [early_stopping],\n",
    "        validation_data = validation_data,\n",
    "        verbose = 2\n",
    "    )\n",
    "    \n",
    "    _, accuracy = model.evaluate(test_data)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to log the resuls\n",
    "def run(log_dir, hparams):\n",
    "    \n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'filter_size': 3, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "422/422 - 32s - loss: 0.2883 - accuracy: 0.9164 - val_loss: 0.1108 - val_accuracy: 0.9668 - 32s/epoch - 75ms/step\n",
      "Epoch 2/2\n",
      "422/422 - 28s - loss: 0.0795 - accuracy: 0.9757 - val_loss: 0.0625 - val_accuracy: 0.9810 - 28s/epoch - 67ms/step\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0548 - accuracy: 0.9823\n",
      "--- Starting trial: run-1\n",
      "{'filter_size': 3, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "422/422 - 28s - loss: 1.3627 - accuracy: 0.6289 - val_loss: 0.4988 - val_accuracy: 0.8480 - 28s/epoch - 67ms/step\n",
      "Epoch 2/2\n",
      "422/422 - 30s - loss: 0.4090 - accuracy: 0.8786 - val_loss: 0.3411 - val_accuracy: 0.8993 - 30s/epoch - 70ms/step\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3312 - accuracy: 0.9012\n",
      "--- Starting trial: run-2\n",
      "{'filter_size': 5, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "422/422 - 34s - loss: 0.2484 - accuracy: 0.9291 - val_loss: 0.0738 - val_accuracy: 0.9762 - 34s/epoch - 80ms/step\n",
      "Epoch 2/2\n",
      "422/422 - 33s - loss: 0.0681 - accuracy: 0.9792 - val_loss: 0.0460 - val_accuracy: 0.9867 - 33s/epoch - 78ms/step\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0451 - accuracy: 0.9855\n",
      "--- Starting trial: run-3\n",
      "{'filter_size': 5, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "422/422 - 29s - loss: 1.1428 - accuracy: 0.7148 - val_loss: 0.4351 - val_accuracy: 0.8677 - 29s/epoch - 70ms/step\n",
      "Epoch 2/2\n",
      "422/422 - 30s - loss: 0.3274 - accuracy: 0.9035 - val_loss: 0.2942 - val_accuracy: 0.9132 - 30s/epoch - 72ms/step\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2656 - accuracy: 0.9248\n",
      "--- Starting trial: run-4\n",
      "{'filter_size': 7, 'optimizer': 'adam'}\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000215A31181F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000215A31181F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 - 28s - loss: 0.2444 - accuracy: 0.9305 - val_loss: 0.0760 - val_accuracy: 0.9783 - 28s/epoch - 67ms/step\n",
      "Epoch 2/2\n",
      "422/422 - 27s - loss: 0.0718 - accuracy: 0.9786 - val_loss: 0.0536 - val_accuracy: 0.9835 - 27s/epoch - 63ms/step\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0656 - accuracy: 0.9794\n",
      "--- Starting trial: run-5\n",
      "{'filter_size': 7, 'optimizer': 'sgd'}\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000215A3202A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000215A3202A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 - 28s - loss: 0.9995 - accuracy: 0.7521 - val_loss: 0.4008 - val_accuracy: 0.8917 - 28s/epoch - 66ms/step\n",
      "Epoch 2/2\n",
      "422/422 - 26s - loss: 0.3298 - accuracy: 0.9059 - val_loss: 0.2759 - val_accuracy: 0.9252 - 26s/epoch - 61ms/step\n",
      "1/1 [==============================] - 1s 976ms/step - loss: 0.2619 - accuracy: 0.9276\n"
     ]
    }
   ],
   "source": [
    "# Performing a grid search on the hyperparameters we need to test\n",
    "session_num = 0\n",
    "\n",
    "for filter_size in HP_FILTER_SIZE.domain.values:\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:  # oh look now you must use a NESTED LOOP\n",
    "    \n",
    "        hparams = {\n",
    "            HP_FILTER_SIZE: filter_size,\n",
    "            HP_OPTIMIZER: optimizer\n",
    "        }\n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('--- Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('logs/hparam_tuning/' + run_name, hparams)\n",
    "\n",
    "        session_num += 1\n",
    " # NOW we will need to wait 6 times more because we will train for EACH combination\n",
    "# you can take a shower, play some games, call your girlfriend/boyfriend, drink a beer, listen some music "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing in Tensorboard"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IMPORTANT!!\n",
    "on windows this can create problems when you run it Second time or more, so do this below::\n",
    "open your command window and write this command:\n",
    "taskkill /im tensorboard.exe /f\n",
    "\n",
    "del /q %TMP%\\.tensorboard-info\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9e4eace731cb5d22\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9e4eace731cb5d22\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the Tensorboard extension   # use it for visualization  #my logs for this training!\n",
    "# ( do this everytime you run the code below)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"logs/hparam_tuning\" \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "set smoothing to zero to see exact results\n",
    "you are seeing training and validation  and loss of model\n",
    "\n",
    "go to graph TAB and see\n",
    "this is wheer your model is desribed "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "defaultNotebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
